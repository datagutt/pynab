# Kaldi ASR Options for the Rust Port

## Current Python Implementation

- `nabd/asr.py` streams 16 kHz PCM frames into `KaldiNNet3OnlineDecoder` via the `py-kaldi-asr` bindings.
- Models live under `/opt/kaldi/model/` with locale-specific directories (for example `kaldi-nabaztag-fr-adapt-r20200203`).
- The decoder runs in a dedicated worker thread, receiving audio chunks and returning the best hypothesis on demand.
- Installation scripts fetch pre-built Kaldi bundles and ensure `py-kaldi-asr` wheel compatibility.

Any Rust replacement must preserve these runtime and deployment characteristics to remain drop-in compatible.

## Functional Expectations for a Rust ASR Layer

- Load Kaldi neural-network (TDNN/FST) models adapted for Nabaztag locales.
- Support incremental/streaming decoding from raw PCM buffers (16 kHz, mono).
- Offer low-latency partial/final hypotheses equivalent to `get_decoded_string`.
- Run under constrained ARM hardware (Raspberry Pi class) with minimal additional dependencies.
- Provide an ergonomic Rust API that integrates with the upcoming `nabd` rewrite plan (`docs/rust-implementation.md`).

## Compatibility with Current Nabaztag Models

- The existing artifacts generated by `asr/adapt-model.sh` (`kaldi-nabaztag-*-adapt-r*.tar.xz`) follow the online2 layout used by `py-kaldi-asr` (`model/final.mdl`, `model/graph/HCLG.fst`, speaker i-vectors, etc.).
- Any replacement must continue to consume those bundles or provide a reproducible conversion pipeline so that new locales can still be trained with the existing tooling.

## Hardware Support Constraints

- Project requirement (October 2025): the ASR stack must run on Raspberry Pi Zero W and Zero 2 W targets deployed in the field.
- Vosk's current binary distribution explicitly supports Raspberry Pi 3/4/5 (ARMv7/AArch64) and excludes Pi Zero-class devices (ARMv6) because prebuilt `libvosk` binaries are not shipped for that architecture.
- Recent regressions observed on Zero 2 W builds indicate the packaged runtime no longer executes reliably on that board even when using the armv7l wheel. Treat Vosk as unsupported for both Zero variants until upstream reinstates compatible builds.
- Any selected backend therefore needs maintainable cross-compilation paths for ARMv6 and ARMv7 with limited RAM footprints (<512 MB at runtime).

## Candidate Rust Options

### 1. Kaldi Online Decoder via Targeted FFI

- Reuse the current Nabaztag `online2` models and the proven decoding graph by exposing a thin Rust wrapper over the Kaldi C++ APIs (for example through `cxx` or `autocxx`).
- We already operate this stack today through Python bindings (`nabd/asr.py`), so porting to Rust becomes an integration task rather than a model rewrite.
- Cross-compiling Kaldi for Raspberry Pi 2/3 has established community guidance, which can be adapted for Zero 2 W deployments; Pi Zero W builds remain possible albeit resource constrained.
- Downsides: complex build scripts, large dependency surface, and the need to curate a minimal shared library to keep deployment sizes manageable.

### 2. PocketSphinx + Grammar-Driven Decoder

- Lightweight CMU Sphinx engine with Rust bindings available via `pocketsphinx` crate (or FFI against `libsphinxbase`).
- Works on low-powered Raspberry Pi Zero-class hardware and already supports grammar-constrained recognition that matches Nabaztag's limited vocabulary use-cases.
- Requires acoustic model retraining or adaptation to achieve parity with the existing Kaldi-based voice recognition quality.
- Strength lies in simpler build tooling and minimal runtime footprint compared with the full Kaldi stack.

### 3. Vosk Safe Bindings (`vosk` crate)

- Remains an attractive option for larger Raspberry Pi targets thanks to its ergonomic API and Kaldi-derived runtime.
- Currently blocked on the Zero W / Zero 2 W requirement because upstream packages no longer ship binaries that execute on those boards; reevaluate if that situation changes.
- If support returns, the Rust API surface (shown below) still aligns with the desired streaming decoder abstractions:

```rust
use vosk::{Model, Recognizer};

let model = Model::new("/opt/pynab/vosk-model")?;
let mut recognizer = Recognizer::new(&model, 16_000.0)?;
recognizer.accept_waveform(&pcm_samples)?;
let result = recognizer.partial_result()?; // or final_result()
```

- We would need a conversion tool to reshape the existing Nabaztag models into the Vosk directory layout before piloting.

### 4. Kaldi Native Feature Extractor (`knf-rs` / `kaldi-native-fbank`)

- Provides Rust bindings to Kaldi's MFCC/filter-bank front-end.
- Useful for audio feature generation but does not include an HCLG decoder, lattice search, or symbol table management.
- Could serve as a building block for bespoke decoder logic, but would require significant additional effort (porting Kaldi's decoder or integrating with another engine).

## Recommendation

- Elevate the Kaldi FFI path as the primary Rust migration target so we keep parity with the existing Python decoder on all supported boards.
- Spin up a feasibility spike to generate a minimal `libkaldi-online2-lite.so` bundle for ARMv6/ARMv7 and expose the subset of APIs required by `ASR.decode_chunk` and `get_decoded_string`.
- In parallel, prototype PocketSphinx with the current grammars to evaluate accuracy trade-offs on Zero-class hardware; this gives us a contingency plan with a significantly smaller footprint.
- Track the Vosk roadmap and reintroduce it only if upstream reinstates reliable Zero-compatible packages; meanwhile document the blocker so future contributors avoid dead ends.
- Continue to monitor `knf-rs` and related projects as potential future enhancements if we later decide to own the full feature pipeline.

## Open Questions

- What is the minimal Kaldi surface area we need to wrap for feature/decoder parity, and can we slim the shared library below 100 MB for Zero-class deployments?
- Which build toolchain (native cross-compilation vs. Docker-based) yields reproducible ARMv6/ARMv7 artifacts without multi-hour CI jobs?
- How far does PocketSphinx fall behind the current Kaldi setup in real-world tests, and can grammar tuning close the gap?
- Should the Rust API mirror the existing `get_decoded_string` pull model or adopt a streaming callback that better suits async Rust services?
- Under what conditions would we reevaluate Vosk (e.g., upstream ARMv6 binaries, community-maintained forks), and how do we detect that early?

Document authored October 5, 2025.
